# **Papers Reading List.**
- This is a collection of papers aiming at reducing model sizes or the implementation of accelerator for Machine Learning, expecially deep neural networks.
- **Notes can be found in my personal [blog](https://zhishengwang.github.io/Neural-Network-Notes/).**

##  **Network Compression**

### **Parameter Sharing**
- **structured matrices**
   - Structured Convolution Matrices for Energy-efficient Deep learning([pdf](http://arxiv.org/abs/1606.02407))
   - Structured Transforms for Small-Footprint Deep Learning([pdf](http://papers.nips.cc/paper/5869-structured-transforms-for-small-footprint-deep-learning))
- **Hashing**
   - Functional Hashing for Compressing Neural Networks([pdf](http://arxiv.org/abs/1605.06560))
   - Compressing Neural Networks with the Hashing Trick([pdf](http://www.jmlr.org/proceedings/papers/v37/chenc15.pdf))

### **Teacher-Student Mechanism (Distilling)**

### **Fixed-precision training and storage**

### **Low-rank matrix factorization**

### **Sparsity regularizers & Pruning**
